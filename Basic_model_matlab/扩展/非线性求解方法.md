#非线性求解方法
### 1. 梯度下降法
#梯度下降法

梯度下降法是一种优化算法，用于寻找函数的局部最小值。其基本思想是沿着函数梯度的反方向迭代更新参数，以逐步逼近最优解。

- **步骤**：
  1. 选择初始点 \(x_0\)。
  2. 计算梯度 \( \nabla f(x) \)。
  3. 更新参数：\( x_{n+1} = x_n - \alpha \nabla f(x_n) \)，其中 \( \alpha \) 是学习率。
  4. 重复步骤 2 和 3，直到满足停止条件。

- **优缺点**：
  - 优点：简单易实现，适用于大规模问题。
  - 缺点：可能收敛到局部最优解，学习率选择不当可能导致收敛慢或不收敛。

### matlab


```matlab
function [x, fval] = gradientDescent(f, gradf, x0, alpha, tol, maxIter)
    x = x0;
    for k = 1:maxIter
        x_new = x - alpha * gradf(x);
        if norm(x_new - x) < tol
            break;
        end
        x = x_new;
    end
    fval = f(x);
end
% 示例
f = @(x) (x(1)-3)^2 + (x(2)-2)^2; % 目标函数
gradf = @(x) [2*(x(1)-3); 2*(x(2)-2)]; % 梯度
[x_min, f_min] = gradientDescent(f, gradf, [0; 0], 0.1, 1e-6, 1000);
```


### 2. **牛顿法**
#牛顿法 

牛顿法是一种用于求解非线性方程和优化问题的迭代方法。它利用二阶导数信息（海森矩阵）来加速收敛。

- **步骤**：
  1. 选择初始点 \(x_0\)。
  2. 计算目标函数的梯度和海森矩阵。
  3. 更新参数：\( x_{n+1} = x_n - H^{-1} \nabla f(x_n) \)，其中 \(H\) 是海森矩阵。
  4. 重复步骤 2 和 3，直到满足停止条件。

- **优缺点**：
  - 优点：收敛速度快，尤其是在接近最优解时。
  - 缺点：需要计算海森矩阵，计算复杂度高，且可能在某些情况下不收敛。
### matlab

```matlab
function [x, fval] = newtonMethod(f, gradf, hessf, x0, tol, maxIter)
    x = x0;
    for k = 1:maxIter
        H = hessf(x);
        g = gradf(x);
        x_new = x - H\g; % 解方程 H * delta = g
        if norm(x_new - x) < tol
            break;
        end
        x = x_new;
    end
    fval = f(x);
end

% 示例
f = @(x) (x(1)-3)^2 + (x(2)-2)^2; % 目标函数
gradf = @(x) [2*(x(1)-3); 2*(x(2)-2)]; % 梯度
hessf = @(x) [2, 0; 0, 2]; % 海森矩阵
[x_min, f_min] = newtonMethod(f, gradf, hessf, [0; 0], 1e-6, 1000);
```

### 3. **遗传算法**
#遗传算法 

遗传算法是一种基于自然选择和遗传学原理的优化算法，适用于复杂的优化问题，尤其是在解空间较大或不连续时。

- **步骤**：
  1. 初始化种群（随机生成一组解）。
  2. 评估每个个体的适应度。
  3. 选择适应度高的个体进行交叉和变异，生成新一代种群。
  4. 重复步骤 2 和 3，直到满足停止条件。

- **优缺点**：
  - 优点：适用于多峰和复杂的搜索空间，能够避免局部最优。
  - 缺点：收敛速度较慢，参数设置（如交叉率、变异率）对结果影响较大。
### matlab

```matlab
function bestSolution = geneticAlgorithm(objFun, nPop, nGen, nVar)
    % 初始化种群
    population = rand(nPop, nVar);
    for gen = 1:nGen
        fitness = arrayfun(@(i) -objFun(population(i, :)), 1:nPop); % 适应度
        [~, idx] = sort(fitness); % 排序
        population = population(idx, :); % 按适应度排序
        
        % 选择和交叉
        for i = 1:2:nPop
            parent1 = population(i, :);
            parent2 = population(i+1, :);
            crossoverPoint = randi(nVar);
            population(i, crossoverPoint:end) = parent2(crossoverPoint:end);
            population(i+1, crossoverPoint:end) = parent1(crossoverPoint:end);
        end
        
        % 变异
        mutationRate = 0.1;
        for i = 1:nPop
            if rand < mutationRate
                mutationPoint = randi(nVar);
                population(i, mutationPoint) = rand; % 随机变异
            end
        end
    end
    bestSolution = population(1, :); % 最优解
end

% 示例
objFun = @(x) (x(1)-3)^2 + (x(2)-2)^2; % 目标函数
bestSolution = geneticAlgorithm(objFun, 100, 50, 2);
```

### 4. **拉格朗日乘数法**
#拉格朗日乘数法

拉格朗日乘数法是一种用于求解带约束优化问题的数学方法。它通过引入拉格朗日乘数，将约束条件融入目标函数中。

- **步骤**：
  1. 定义拉格朗日函数：\( L(x, \lambda) = f(x) + \lambda g(x) \)，其中 \(g(x) = 0\) 是约束条件。
  2. 计算拉格朗日函数对 \(x\) 和 \(\lambda\) 的偏导数，并设为零。
  3. 解方程组，得到优化解和拉格朗日乘数。

- **优缺点**：
  - 优点：能够有效处理等式约束问题。
  - 缺点：对于不等式约束，需要进一步的扩展（如KKT条件）。

以下是用 MATLAB 实现梯度下降法、牛顿法、遗传算法和拉格朗日乘数法的示例代码：

### matlab

```matlab
function [x, lambda] = lagrangeMultiplier(f, g, x0)
    syms x1 x2 lambda;
    L = f(x1, x2) + lambda * g(x1, x2);
    gradL = gradient(L, [x1, x2, lambda]);
    sol = solve(gradL == 0, [x1, x2, lambda]);
    x = [double(sol.x1), double(sol.x2)];
    lambda = double(sol.lambda);
end

% 示例
f = @(x1, x2) (x1-3)^2 + (x2-2)^2; % 目标函数
g = @(x1, x2) x1 + x2 - 5; % 约束条件
[x_opt, lambda] = lagrangeMultiplier(f, g, [0, 0]);
```
